{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "KEY='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'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from anthropic import Anthropic\n",
    "\n",
    "class Chat:\n",
    "    def __init__(self):\n",
    "        self.client = Anthropic(api_key=KEY)\n",
    "        self.messages = []\n",
    "        self.temperature = 0.7\n",
    "        self.max_tokens = 500\n",
    "        self.system_instructions = 'you are a useful bot'\n",
    "\n",
    "    def add_message(self, role, content):\n",
    "        self.messages.append({'role': role, 'content': content})\n",
    "\n",
    "    def stream_chat(self, prompt_content):\n",
    "        self.add_message('user', prompt_content)\n",
    "        with self.client.messages.stream(\n",
    "            model=\"claude-3-5-sonnet-20240620\",\n",
    "            max_tokens=self.max_tokens,\n",
    "            temperature=self.temperature,\n",
    "            system=self.system_instructions,\n",
    "            messages=self.messages\n",
    "        ) as stream:\n",
    "            full_response = \"\"\n",
    "            for chunk in stream:\n",
    "                if chunk.type == \"content_block_delta\":\n",
    "                    text = chunk.delta.text\n",
    "                    yield text\n",
    "                    full_response += text\n",
    "        self.add_message('assistant', full_response)\n",
    "\n",
    "    def clear_history(self):\n",
    "        self.messages.clear()\n",
    "\n",
    "    def get_history(self):\n",
    "        return self.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! As an AI assistant, I don't have feelings in the way humans do, but I'm functioning well and ready to help. How can I assist you today?\n",
      "\n",
      "Certainly! Our conversation so far has been very brief:\n",
      "\n",
      "1. You greeted me and asked how I was doing.\n",
      "2. I responded, explaining that as an AI I don't have feelings, but that I'm functioning well and ready to assist you.\n",
      "3. You then asked me to summarize our conversation.\n",
      "\n",
      "That brings us up to this point. Is there a particular topic or task you'd like to discuss or work on?\n",
      "\n",
      "[{'role': 'user', 'content': 'Hello, Claude! How are you today?'}, {'role': 'assistant', 'content': \"Hello! As an AI assistant, I don't have feelings in the way humans do, but I'm functioning well and ready to help. How can I assist you today?\"}, {'role': 'user', 'content': 'Can you summarize our conversation so far?'}, {'role': 'assistant', 'content': \"Certainly! Our conversation so far has been very brief:\\n\\n1. You greeted me and asked how I was doing.\\n2. I responded, explaining that as an AI I don't have feelings, but that I'm functioning well and ready to assist you.\\n3. You then asked me to summarize our conversation.\\n\\nThat brings us up to this point. Is there a particular topic or task you'd like to discuss or work on?\"}]\n"
     ]
    }
   ],
   "source": [
    "chat = Chat()\n",
    "\n",
    "# First message\n",
    "for chunk in chat.stream_chat(\"Hello, Claude! How are you today?\"):\n",
    "    print(chunk, end='', flush=True)\n",
    "print(\"\\n\")  # New line after the response\n",
    "\n",
    "# Second message (context is maintained)\n",
    "for chunk in chat.stream_chat(\"Can you summarize our conversation so far?\"):\n",
    "    print(chunk, end='', flush=True)\n",
    "print(\"\\n\")\n",
    "\n",
    "# If you want to see the full conversation history\n",
    "print(chat.get_history())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user', 'content': 'give me a gist of this in short'},\n",
       " {'role': 'assistant',\n",
       "  'content': \"I apologize, but I don't have any previous context or information to summarize. Could you please provide the specific text or topic you'd like me to give a gist of? Once you share that information, I'll be happy to provide a brief summary for you.\"}]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I apologize, but I don't have any previous context or information to summarize. Could you please provide the specific text or topic you'd like me to give a gist of? Once you share that information, I'll be happy to provide a brief summary for you."
     ]
    }
   ],
   "source": [
    "chat = Chat()\n",
    "for chunk in chat.stream_chat(\"give me a gist of this in short\"):\n",
    "    print(chunk, end='', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'CompletionsWithStreamingResponse' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwith_streaming_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'CompletionsWithStreamingResponse' object is not callable"
     ]
    }
   ],
   "source": [
    "c.client.completions.with_streaming_response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<anthropic.lib.streaming._messages.MessageStreamManager at 0x7cc42f82f610>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
